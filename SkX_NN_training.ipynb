{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for training the NN. Training data stack should already be made, but noise can/will be added here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPUs available\n",
      "Running on GPU (index) 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"torch.nn.functional\")\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from image_helpers import * \n",
    "from datatransform import datatransform, training_log\n",
    "\n",
    "from smallUnet import *\n",
    "from skyrm_find_CNN import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu = 0\n",
    "    print(f\"There are {torch.cuda.device_count()} GPUs available\")\n",
    "    print(f\"Running on GPU (index) {gpu}\")\n",
    "else:\n",
    "    gpu = 'cpu'\n",
    "    print(\"GPU is not available, will run on CPU.\")\n",
    "    \n",
    "savedir = Path('./NN_trained/').absolute()\n",
    "today = datetime.today().strftime('%y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_name = f\"skNet_batch1_{today}\"\n",
    "savedir = './NN_trained/' # dir to save results\n",
    "nn_path = os.path.join(savedir, NN_name + \"_final.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If loading a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_path = savedir / \"skNet_batch1_210921_final.pt\"\n",
    "model = smallUnet()\n",
    "model.cuda(gpu)\n",
    "model.load_state_dict(torch.load(nn_path))\n",
    "model.eval()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  ### need to do this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = np.load('./training_data/batch1/200318_combrot.npz')\n",
    "test_split = 0.2\n",
    "batch_size = 64 \n",
    "epochs = 600 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size Images, Labels:\n",
      " ((3000, 256, 256), (3000, 256, 256))\n",
      "Number training images: 2400\n",
      "Number test images: 600\n"
     ]
    }
   ],
   "source": [
    "images_load = dataset['Images']\n",
    "labels_load = (dataset['Labels']>0.1).astype('int') # forgot to threshold the training data, \n",
    "# binary classification so this works\n",
    "assert images_load.shape[0] == labels_load.shape[0]\n",
    "print(f\"Total size Images, Labels:\\n {images_load.shape, labels_load.shape}\")\n",
    "print(f\"Number training images: {int(images_load.shape[0]*(1-test_split))}\")\n",
    "print(f\"Number test images: {int(images_load.shape[0]*(test_split))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "# apply noise to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training params file to:\n",
      " /home/amccray/code/SkX_NN/NN_trained/skNet_batch1_220208_training_data_params.txt\n",
      "(3000, 1, 256, 256) (3000, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# For a single class case, we still need to explicitly specify the single channel\n",
    "labels_load2 = labels_load[..., None] if np.ndim(labels_load) == 3 else labels_load\n",
    "# Number of channels in masked data (the training images have a single channel)\n",
    "ch = labels_load2.shape[-1]\n",
    "# Define image distortion/noise parameters\n",
    "zoom = False  # zoom factor\n",
    "poisson = [10, 45]  # P noise range (scaled units)\n",
    "gauss = [1, 150]  # G noise range (scaled units)\n",
    "blur = [1, 50]  # Blurring range (scaled units)\n",
    "contrast = [3, 18]  # contrast range (< 10 is brighter, > 10 is darker)\n",
    "salt_and_pepper = [0, 20]  # min/max amount of salted/peppered pixels (scaled units)\n",
    "\n",
    "notes = textwrap.dedent(\n",
    "    \"\"\"Trained on rotated Skx data such that tilt axis is along x axis\n",
    "    (contrast is left/right)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "dim_order_in = \"channel_last\"\n",
    "dim_order_out = \"channel_first\"\n",
    "seed = 42\n",
    "zoom = False\n",
    "rotation = False\n",
    "\n",
    "# Run the augmentor\n",
    "imaug = datatransform(\n",
    "    n_channels=ch,\n",
    "    dim_order_in=dim_order_in,\n",
    "    dim_order_out=dim_order_out,\n",
    "    gauss_noise=gauss,\n",
    "    poisson_noise=poisson,\n",
    "    salt_and_pepper=salt_and_pepper,\n",
    "    contrast=contrast,\n",
    "    blur=blur,\n",
    "    zoom=zoom,\n",
    "    rotation=rotation,\n",
    "    seed=seed,\n",
    "    squeeze_channels=True,\n",
    "    classifier=True,\n",
    ")\n",
    "\n",
    "images_noise, labels_noise = imaug.run(images_load, labels_load2)\n",
    "\n",
    "training_log(\n",
    "    NN_name,\n",
    "    savedir,\n",
    "    images_shape=images_load.shape,\n",
    "    labels_shape=labels_load2.shape,\n",
    "    test_split=test_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    n_channels=ch,\n",
    "    dim_order_in=dim_order_in,\n",
    "    dim_order_out=dim_order_out,\n",
    "    gauss_noise=gauss,\n",
    "    poisson_noise=poisson,\n",
    "    salt_and_pepper=salt_and_pepper,\n",
    "    contrast=contrast,\n",
    "    blur=blur,\n",
    "    zoom=zoom,\n",
    "    rotation=rotation,\n",
    "    seed=seed,\n",
    "    notes=notes,\n",
    ")\n",
    "\n",
    "labels_noise = labels_noise.squeeze()\n",
    "print(images_noise.shape, labels_noise.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Look at some of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945f6b2d86e644079e49b726f4e9d412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=30\n",
    "n = 5\n",
    "\n",
    "n = n + 1\n",
    "fig = plt.figure( figsize=(15, 8))\n",
    "for i in range(1, n):   \n",
    "    ax = fig.add_subplot(3, n, i)\n",
    "    ax.imshow(images_load[i+s-1], cmap='gray')\n",
    "    ax.set_title(\"Original image\" + str(i-1), fontsize=10)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, labelbottom=False)  \n",
    "    if i != 1: \n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)  \n",
    "        \n",
    "    ax = fig.add_subplot(3, n, i+n)\n",
    "    ax.imshow(images_noise[i+s-1,0,:,:], cmap='gray')\n",
    "    ax.set_title('Augmented image ' + str(i-1), fontsize=10)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, labelbottom=False)    \n",
    "    if i != 1: \n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)  \n",
    "    \n",
    "    ax = fig.add_subplot(3, n, i+2*n)\n",
    "    ax.imshow(labels_noise[i+s-1], cmap='jet', interpolation='Gaussian')\n",
    "#     ax.imshow(images_noise[i+s-1,0,:,:], cmap='gray', alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax.set_title('Ground truth ' + str(i), fontsize=10)\n",
    "    if i != 1: \n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)  \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1, 256, 256) (2400, 256, 256) (600, 1, 256, 256) (600, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images_all, images_test_all, labels_all, labels_test_all = train_test_split(\n",
    "    images_noise, labels_noise, test_size=test_split)\n",
    "print(images_all.shape, labels_all.shape, images_test_all.shape, labels_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "# initialize and train a new CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rng_seed(42) # for reproducibility\n",
    "\n",
    "# Initialize a model\n",
    "model = smallUnet()\n",
    "model.cuda(gpu)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image stack shape:  (2400, 1, 256, 256)\n",
      "batch stack shape:  (37, 64, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "n_train_batches, _ = np.divmod(labels_all.shape[0], batch_size)\n",
    "n_test_batches, _ = np.divmod(labels_test_all.shape[0], batch_size)\n",
    "images_allb = np.split(\n",
    "    images_all[:n_train_batches*batch_size], n_train_batches)\n",
    "labels_allb = np.split(\n",
    "    labels_all[:n_train_batches*batch_size], n_train_batches)\n",
    "images_test_allb = np.split(\n",
    "    images_test_all[:n_test_batches*batch_size], n_test_batches)\n",
    "labels_test_allb = np.split(\n",
    "    labels_test_all[:n_test_batches*batch_size], n_test_batches)\n",
    "print('image stack shape: ', np.shape(images_all))\n",
    "print('batch stack shape: ', np.shape(images_allb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_loss = 50 # print loss every m-th epoch.\n",
    "# Generate sequence of random numbers for batch selection during training/testing\n",
    "batch_ridx = [np.random.randint(0, len(images_allb)) for _ in range(epochs)]\n",
    "batch_ridx_t = [np.random.randint(0, len(images_test_allb)) for _ in range(epochs)]\n",
    "# Start training\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):  \n",
    "    model.train() # put in training mode \n",
    "    # Generate batch of training images with corresponding ground truth\n",
    "    images = images_allb[batch_ridx[e]]\n",
    "    labels = labels_allb[batch_ridx[e]]\n",
    "    # Transform images and ground truth to torch tensors and move to GPU\n",
    "    images = torch.from_numpy(images).float()\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "    images, labels = images.cuda(gpu), labels.cuda(gpu) \n",
    "    # Forward --> Backward --> Optimize\n",
    "    optimizer.zero_grad() \n",
    "    prob = model.forward(images)\n",
    "    loss = criterion(prob, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "    # Now test the current model state using test data\n",
    "    model.eval() # turn off batch norm and/or dropout units\n",
    "    images_ = images_test_allb[batch_ridx_t[e]]\n",
    "    labels_ = labels_test_allb[batch_ridx_t[e]]\n",
    "    images_ = torch.from_numpy(images_).float()\n",
    "    labels_ = torch.from_numpy(labels_).long()\n",
    "    images_, labels_ = images_.cuda(gpu), labels_.cuda(gpu)\n",
    "    with torch.no_grad(): # deactivate autograd engine during testing (saves memory)\n",
    "        prob = model.forward(images_)\n",
    "        loss = criterion(prob, labels_)\n",
    "        test_losses.append(loss.item())\n",
    "    # Print statistics\n",
    "    if e == 0 or (e+1) % print_loss == 0:\n",
    "        print('Epoch {:3} .... Training loss: {:8} .... Test loss: {:8}'.format(\n",
    "            e+1, np.around(train_losses[-1], 8), np.around(test_losses[-1], 8))\n",
    "        )\n",
    "    # Save the best model weights\n",
    "    if e > 100 and test_losses[-1] < min(test_losses[: -1]):\n",
    "        torch.save(model.state_dict(), \n",
    "                   os.path.join(savedir, NN_name + '.pt'))\n",
    "# Save final weights\n",
    "torch.save(model.state_dict(), \n",
    "           os.path.join(savedir, NN_name + '_final.pt'))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_losses, label='train')\n",
    "ax.plot(test_losses, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(f\"./NN_trained/Training_loss_{NN_name}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## viewing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k, im = 2, 8 # batch, image\n",
    "test_img = images_test_allb[k][im]\n",
    "test_lbl = labels_test_allb[k][im]\n",
    "# Convert to 4D tensor (required, even if it is a single image)\n",
    "test_img = test_img[np.newaxis, ...]\n",
    "# Convert to pytorch format and move to GPU\n",
    "test_img_ = torch.from_numpy(test_img).float().cuda()\n",
    "# make a prediction\n",
    "prediction = model.forward(test_img_)\n",
    "prediction = F.softmax(prediction, dim=1).cpu().detach().numpy()\n",
    "prediction = np.transpose(prediction, [0, 2, 3, 1]) # rearange dimensions for plotting\n",
    "# plot results\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.imshow(test_img[0,0], cmap='gray')\n",
    "ax2.imshow(prediction[0,:,:,1], cmap='gray', Interpolation='Gaussian')\n",
    "ax1.set_title('Test image')\n",
    "ax2.set_title('Model prediction')\n",
    "\n",
    "show_im(test_img[0,0] + prediction[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a NN on a full image\n",
    "Skip to here if already have a trained NN \n",
    "For actual experimental data, I have a workflow for bringing in the raw TEM images, filtering them, determining the tilt axis and compensating for tilt angle, etc., but for this example just using an already processed image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4bc316cc7b40639a49fe300f9332ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_im = np.load(\"./test_data/150K_test.npy\")\n",
    "tilt_dir = 132.137 # tilt axis\n",
    "show_im(test_im, title=\"Example image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66421cb9af9744a6ad7944f9337ef00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0b34498ee3440086776e8bdcdb63e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = trained_NN(nn_path, cuda=True)\n",
    "centers = model.find_skyrms(test_im, tilt_dir, thresh=0.3, gpu=gpu)\n",
    "show_im(model.prediction[:,:,0], \"Model prediction\", simple=True)\n",
    "show_im_peaks(test_im, centers, title=\"Skyrmion locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
