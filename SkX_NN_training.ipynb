{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for training the NN. Training data stack should already be made, but noise can/will be added here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPUs available\n",
      "Running on GPU 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"torch.nn.functional\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../helpers/\")\n",
    "from image_helpers import * \n",
    "\n",
    "from datatransform import datatransform \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from smallUnet import *\n",
    "from skyrm_find_CNN import *\n",
    "from image_helpers import * \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu = 0\n",
    "    print(f\"There are {torch.cuda.device_count()} GPUs available\")\n",
    "    print(f\"Running on GPU {gpu}\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    \n",
    "today = datetime.today().strftime('%y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_name = f\"skNet_batch1_{today}\"\n",
    "# NN_name = f\"skNet_batch1_210830\"\n",
    "savedir = './NN_trained/' # dir to save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### If loading a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for smallUnet:\n\tMissing key(s) in state_dict: \"upsample_block1.upsample2x.weight\", \"upsample_block1.upsample2x.bias\", \"upsample_block2.upsample2x.weight\", \"upsample_block2.upsample2x.bias\", \"upsample_block3.upsample2x.weight\", \"upsample_block3.upsample2x.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61537/2584578759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmallUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for smallUnet:\n\tMissing key(s) in state_dict: \"upsample_block1.upsample2x.weight\", \"upsample_block1.upsample2x.bias\", \"upsample_block2.upsample2x.weight\", \"upsample_block2.upsample2x.bias\", \"upsample_block3.upsample2x.weight\", \"upsample_block3.upsample2x.bias\". "
     ]
    }
   ],
   "source": [
    "nn_path = \"./NN_trained/skNet_batch1_210830_final.pt\"\n",
    "model = smallUnet()\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(nn_path))\n",
    "model.eval()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # lr is a learniing rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('./training_data/batch1/200318_combrot.npz')\n",
    "test_split = 0.2\n",
    "batch_size = 64 \n",
    "epochs = 600 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size Images, Labels:\n",
      " ((3000, 256, 256), (3000, 256, 256))\n",
      "Number training images: 2400\n",
      "Number test images: 600\n"
     ]
    }
   ],
   "source": [
    "images_load = dataset['Images']\n",
    "labels_load = (dataset['Labels']>0.1).astype('int') # forgot to threshold the training data, \n",
    "# binary classification so this works\n",
    "assert images_load.shape[0] == labels_load.shape[0]\n",
    "print(f\"Total size Images, Labels:\\n {images_load.shape, labels_load.shape}\")\n",
    "print(f\"Number training images: {int(images_load.shape[0]*(1-test_split))}\")\n",
    "print(f\"Number test images: {int(images_load.shape[0]*(test_split))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# apply noise to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def training_log(name=None, savedir=None, images=None, labels=None, test_split=None, \n",
    "                 batch_size=None, epochs=None, n_channels=None, dim_order_in=None, \n",
    "                 dim_order_out=None, gauss_noise=None, poisson_noise=None, \n",
    "                 salt_and_pepper=None, contrast=None, blur=None, zoom=None, \n",
    "                 rotation=None, seed=None, notes=None):\n",
    "    \n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    \n",
    "    log_name = os.path.join(savedir, name + \"_training_data_params.txt\")\n",
    "    with open(log_name, \"w\") as txt:\n",
    "        txt.write(textwrap.dedent(f\"\"\"\\\n",
    "        NN name: {name}\n",
    "        final NN savepath: {os.path.join(os.path.abspath(savedir), name + '_final.pt')}\n",
    "        images shape: {np.shape(images)}\n",
    "        labels shape: {np.shape(labels)}\n",
    "        test split: {test_split}\n",
    "        batch size: {batch_size}\n",
    "        epochs: {epochs}\n",
    "        \n",
    "        number channels: {n_channels}\n",
    "        dim_order_in: {dim_order_in}\n",
    "        dim_order_out: {dim_order_out}\n",
    "        \n",
    "        Noise added to training/test data using atomai.transforms.datatransform():\n",
    "        gauss_noise: {gauss_noise}\n",
    "        poisson_noise: {poisson_noise}\n",
    "        salt_and_pepper: {salt_and_pepper}\n",
    "        contrast: {contrast}\n",
    "        blur: {blur}\n",
    "        zoom: {zoom}\n",
    "        rotation: {rotation}\n",
    "        seed: {seed}\n",
    "        \n",
    "        notes: {notes}\"\"\"))\n",
    "    print(f\"Saved training params file to:\\n\", os.path.abspath(log_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training params file to:\n",
      " /home/amccray/code/SkX_NN/NN_trained/skNet_batch1_210921_training_data_params.txt\n",
      "(3000, 1, 256, 256) (3000, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# For a single class case, we still need to explicitly specify the single channel\n",
    "labels_load2 = labels_load[..., None] if np.ndim(labels_load) == 3 else labels_load\n",
    "# Number of channels in masked data (the training images have a single channel)\n",
    "ch = labels_load2.shape[-1]\n",
    "# Define image distortion/noise parameters\n",
    "zoom = False # zoom factor\n",
    "poisson = [10, 45] # P noise range (scaled units)\n",
    "gauss = [1, 150] # G noise range (scaled units)\n",
    "blur = [1, 50] # Blurring range (scaled units)\n",
    "contrast = [3, 18] # contrast range (< 10 is brighter, > 10 is darker)\n",
    "salt_and_pepper = [0, 20] # min/max amount of salted/peppered pixels (scaled units)\n",
    "\n",
    "notes = textwrap.dedent(\"\"\"\n",
    "Trained on rotated Skx data such that tilt axis is along x axis\n",
    "(contrast is left/right)\n",
    "\"\"\")\n",
    "\n",
    "dim_order_in = 'channel_last'\n",
    "dim_order_out = 'channel_first'\n",
    "seed = 42\n",
    "zoom = False\n",
    "rotation = False\n",
    "\n",
    "# Run the augmentor\n",
    "imaug = datatransform(\n",
    "    n_channels=ch, dim_order_in=dim_order_in, dim_order_out=dim_order_out, \n",
    "    gauss_noise=gauss, poisson_noise=poisson, salt_and_pepper=salt_and_pepper,\n",
    "    contrast=contrast, blur=blur, zoom=zoom, rotation=rotation, seed=seed,\n",
    "    squeeze_channels=True, classifier=True)\n",
    "\n",
    "images_noise, labels_noise = imaug.run(images_load, labels_load2)\n",
    "\n",
    "training_log(NN_name, savedir, images_load, labels_load2, test_split, batch_size,\n",
    "             epochs, ch, dim_order_in, dim_order_out, gauss, poisson, \n",
    "             salt_and_pepper, contrast, blur, zoom, rotation, seed, notes)\n",
    "\n",
    "labels_noise = labels_noise.squeeze()\n",
    "print(images_noise.shape, labels_noise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d83eaf6605944ddbaafd03c14b22103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=30\n",
    "n = 5\n",
    "\n",
    "n = n + 1\n",
    "fig = plt.figure( figsize=(15, 8))\n",
    "for i in range(1, n):   \n",
    "    ax = fig.add_subplot(3, n, i)\n",
    "    ax.imshow(images_load[i+s-1], cmap='gray')\n",
    "    ax.set_title(\"Original image\" + str(i-1), fontsize=10)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, labelbottom=False)  \n",
    "    if i != 1: \n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)  \n",
    "        \n",
    "    ax = fig.add_subplot(3, n, i+n)\n",
    "    ax.imshow(images_noise[i+s-1,0,:,:], cmap='gray')\n",
    "    ax.set_title('Augmented image ' + str(i-1), fontsize=10)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, labelbottom=False)    \n",
    "    if i != 1: \n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)  \n",
    "    \n",
    "    ax = fig.add_subplot(3, n, i+2*n)\n",
    "    ax.imshow(labels_noise[i+s-1], cmap='jet', interpolation='Gaussian')\n",
    "#     ax.imshow(images_noise[i+s-1,0,:,:], cmap='gray', alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax.set_title('Ground truth ' + str(i), fontsize=10)\n",
    "    if i != 1: \n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)  \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 50\n",
    "# plt.figure(figsize=(5, 5), dpi=100)\n",
    "# plt.imshow(images_load[k], cmap='gray')\n",
    "# # plt.imshow(labels_load[k], cmap='jet', alpha=.4, interpolation='Gaussian')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(5, 5), dpi=100)\n",
    "# plt.imshow(images_noise[k][0], cmap='gray')\n",
    "# # plt.imshow(labels_noise[k], cmap='jet', alpha=.4, interpolation='Gaussian')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1, 256, 256) (2400, 256, 256) (600, 1, 256, 256) (600, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "images_all, images_test_all, labels_all, labels_test_all = train_test_split(\n",
    "    images_noise, labels_noise, test_size=test_split)\n",
    "print(images_all.shape, labels_all.shape, images_test_all.shape, labels_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### or load already noised training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dataset = np.load('./training_data/full_training.npz')\n",
    "# images_all = dataset['X_train']\n",
    "# labels_all = dataset['y_train'].squeeze()\n",
    "# images_test_all = dataset['X_test']\n",
    "# labels_test_all = dataset['y_test'].squeeze()\n",
    "# print(images_all.shape, labels_all.shape, images_test_all.shape, labels_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# initialize and train a new CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed(42) # for reproducibility\n",
    "\n",
    "# Initialize a model\n",
    "model = smallUnet()\n",
    "model.cuda(gpu)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image stack shape:  (2400, 1, 256, 256)\n",
      "batch stack shape:  (37, 64, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "n_train_batches, _ = np.divmod(labels_all.shape[0], batch_size)\n",
    "n_test_batches, _ = np.divmod(labels_test_all.shape[0], batch_size)\n",
    "images_allb = np.split(\n",
    "    images_all[:n_train_batches*batch_size], n_train_batches)\n",
    "labels_allb = np.split(\n",
    "    labels_all[:n_train_batches*batch_size], n_train_batches)\n",
    "images_test_allb = np.split(\n",
    "    images_test_all[:n_test_batches*batch_size], n_test_batches)\n",
    "labels_test_allb = np.split(\n",
    "    labels_test_all[:n_test_batches*batch_size], n_test_batches)\n",
    "print('image stack shape: ', np.shape(images_all))\n",
    "print('batch stack shape: ', np.shape(images_allb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 .... Training loss: 0.64927316 .... Test loss: 0.58615661\n",
      "Epoch  50 .... Training loss: 0.37310037 .... Test loss: 0.31674543\n",
      "Epoch 100 .... Training loss: 0.24385744 .... Test loss: 0.21978807\n",
      "Epoch 150 .... Training loss: 0.15187161 .... Test loss: 0.13320003\n",
      "Epoch 200 .... Training loss: 0.10539028 .... Test loss: 0.09378328\n",
      "Epoch 250 .... Training loss: 0.08344754 .... Test loss: 0.07591189\n",
      "Epoch 300 .... Training loss: 0.06866263 .... Test loss: 0.07165945\n",
      "Epoch 350 .... Training loss: 0.06031501 .... Test loss: 0.05663317\n",
      "Epoch 400 .... Training loss: 0.05669961 .... Test loss: 0.05738439\n",
      "Epoch 450 .... Training loss: 0.04054983 .... Test loss: 0.05663821\n",
      "Epoch 500 .... Training loss: 0.04643064 .... Test loss: 0.05181461\n",
      "Epoch 550 .... Training loss: 0.03769507 .... Test loss: 0.05278264\n",
      "Epoch 600 .... Training loss: 0.03836238 .... Test loss: 0.05472685\n"
     ]
    }
   ],
   "source": [
    "print_loss = 50 # print loss every m-th epoch.\n",
    "# Generate sequence of random numbers for batch selection during training/testing\n",
    "batch_ridx = [np.random.randint(0, len(images_allb)) for _ in range(epochs)]\n",
    "batch_ridx_t = [np.random.randint(0, len(images_test_allb)) for _ in range(epochs)]\n",
    "# Start training\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):  \n",
    "    model.train() # put in training mode \n",
    "    # Generate batch of training images with corresponding ground truth\n",
    "    images = images_allb[batch_ridx[e]]\n",
    "    labels = labels_allb[batch_ridx[e]]\n",
    "    # Transform images and ground truth to torch tensors and move to GPU\n",
    "    images = torch.from_numpy(images).float()\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "    images, labels = images.cuda(gpu), labels.cuda(gpu) \n",
    "    # Forward --> Backward --> Optimize\n",
    "    optimizer.zero_grad() \n",
    "    prob = model.forward(images)\n",
    "    loss = criterion(prob, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "    # Now test the current model state using test data\n",
    "    model.eval() # turn off batch norm and/or dropout units\n",
    "    images_ = images_test_allb[batch_ridx_t[e]]\n",
    "    labels_ = labels_test_allb[batch_ridx_t[e]]\n",
    "    images_ = torch.from_numpy(images_).float()\n",
    "    labels_ = torch.from_numpy(labels_).long()\n",
    "    images_, labels_ = images_.cuda(gpu), labels_.cuda(gpu)\n",
    "    with torch.no_grad(): # deactivate autograd engine during testing (saves memory)\n",
    "        prob = model.forward(images_)\n",
    "        loss = criterion(prob, labels_)\n",
    "        test_losses.append(loss.item())\n",
    "    # Print statistics\n",
    "    if e == 0 or (e+1) % print_loss == 0:\n",
    "        print('Epoch {:3} .... Training loss: {:8} .... Test loss: {:8}'.format(\n",
    "            e+1, np.around(train_losses[-1], 8), np.around(test_losses[-1], 8))\n",
    "        )\n",
    "    # Save the best model weights\n",
    "    if e > 100 and test_losses[-1] < min(test_losses[: -1]):\n",
    "        torch.save(model.state_dict(), \n",
    "                   os.path.join(savedir, NN_name + '.pt'))\n",
    "# Save final weights\n",
    "torch.save(model.state_dict(), \n",
    "           os.path.join(savedir, NN_name + '_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bc1b6ccc0b434fa24014e68c37acaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_losses, label='train')\n",
    "ax.plot(test_losses, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viewing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, im = 2, 8 # batch, image\n",
    "test_img = images_test_allb[k][im]\n",
    "test_lbl = labels_test_allb[k][im]\n",
    "# Convert to 4D tensor (required, even if it is a single image)\n",
    "test_img = test_img[np.newaxis, ...]\n",
    "# Convert to pytorch format and move to GPU\n",
    "test_img_ = torch.from_numpy(test_img).float().cuda()\n",
    "# make a prediction\n",
    "prediction = model.forward(test_img_)\n",
    "prediction = F.softmax(prediction, dim=1).cpu().detach().numpy()\n",
    "prediction = np.transpose(prediction, [0, 2, 3, 1]) # rearange dimensions for plotting\n",
    "# plot results\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.imshow(test_img[0,0], cmap='gray')\n",
    "ax2.imshow(prediction[0,:,:,1], cmap='gray', Interpolation='Gaussian')\n",
    "ax1.set_title('Test image')\n",
    "ax2.set_title('Model prediction')\n",
    "\n",
    "show_im(test_img[0,0] + prediction[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a NN on a full image\n",
    "Skip to here if already have a trained NN \n",
    "For actual experimental data, I have a workflow for bringing in the raw TEM images, filtering them, determining the tilt axis and compensating for tilt angle, etc., but for this example just using an already processed image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effda8667999405fabe77ebe57ecf6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_im = np.load(\"./test_data/150K_test.npy\")\n",
    "tilt_dir = 132.137 # tilt axis\n",
    "show_im(test_im, title=\"Example image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for smallUnet:\n\tMissing key(s) in state_dict: \"upsample_block1.upsample2x.weight\", \"upsample_block1.upsample2x.bias\", \"upsample_block2.upsample2x.weight\", \"upsample_block2.upsample2x.bias\", \"upsample_block3.upsample2x.weight\", \"upsample_block3.upsample2x.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61537/3913810592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_final.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_skyrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_im\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Model prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshow_im_peaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Skyrmion locations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/SkX_NN/skyrm_find_CNN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, cuda, gpu)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for smallUnet:\n\tMissing key(s) in state_dict: \"upsample_block1.upsample2x.weight\", \"upsample_block1.upsample2x.bias\", \"upsample_block2.upsample2x.weight\", \"upsample_block2.upsample2x.bias\", \"upsample_block3.upsample2x.weight\", \"upsample_block3.upsample2x.bias\". "
     ]
    }
   ],
   "source": [
    "nn_path = os.path.join(savedir, NN_name + \"_final.pt\")\n",
    "model = trained_NN(nn_path, cuda=True)\n",
    "centers = model.find_skyrms(test_im, tilt_dir, thresh=0.3, gpu=gpu)\n",
    "show_im(model.prediction[:,:,0], \"Model prediction\", simple=True)\n",
    "show_im_peaks(test_im, centers, title=\"Skyrmion locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
